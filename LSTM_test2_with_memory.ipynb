{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "frmoe0F00vCw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        " \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        " \n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#https://github.com/iamirmasoud/energy_consumption_prediction/blob/master/Energy%20consumption%20prediction%20using%20LSTM-GRU%20in%20PyTorch.ipynb\n",
        "\n",
        "#http://www.sefidian.com/2020/01/30/gated-recurrent-unit-gru-with-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibwMknqt00Tw",
        "outputId": "32e1d003-b3ef-4d44-db54-6663178dab0a"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cn3BYG3C01vK"
      },
      "outputs": [],
      "source": [
        "# # Define data root directory\n",
        "# data_dir = \"/content/drive/MyDrive/Colab Notebooks/10DeepLearningRNN_TimeSeries_StockProject/energy/\"\n",
        "# # Visualise how our data looks\n",
        "# dataset = pd.read_csv(data_dir + 'AEP_hourly.csv').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define data root directory\n",
        "data_dir = \"./data/\"\n",
        "# # Visualise how our data looks\n",
        "dataset = pd.read_csv(data_dir + 'AEP_hourly.csv').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqMyJE-T1A3q"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOZ9DBlI022m",
        "outputId": "3e56a155-6804-4ab8-873b-e7421d047f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['est_hourly.paruqet', 'PJMW_hourly.csv', 'pjm_hourly_est.csv', 'PJM_Load_hourly.csv', 'DAYTON_hourly.csv', 'NI_hourly.csv', 'PJME_hourly.csv', 'FE_hourly.csv', 'DOM_hourly.csv', 'EKPC_hourly.csv', 'DEOK_hourly.csv', 'DUQ_hourly.csv', 'AEP_hourly.csv', 'COMED_hourly.csv']\n"
          ]
        }
      ],
      "source": [
        "# Define data root directory\n",
        "print(os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tovWCp5W1FuQ",
        "outputId": "aa526e9b-09c0-4381-b428-bde64e121038"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datetime</th>\n",
              "      <th>DEOK_MW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-12-31 01:00:00</td>\n",
              "      <td>2945.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-12-31 02:00:00</td>\n",
              "      <td>2868.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-12-31 03:00:00</td>\n",
              "      <td>2812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-12-31 04:00:00</td>\n",
              "      <td>2812.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-12-31 05:00:00</td>\n",
              "      <td>2860.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Datetime  DEOK_MW\n",
              "0  2012-12-31 01:00:00   2945.0\n",
              "1  2012-12-31 02:00:00   2868.0\n",
              "2  2012-12-31 03:00:00   2812.0\n",
              "3  2012-12-31 04:00:00   2812.0\n",
              "4  2012-12-31 05:00:00   2860.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv(os.path.join(data_dir, \"DEOK_hourly.csv\")).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMlPwhGP2g-E"
      },
      "source": [
        "# Feature Engineering \n",
        "\n",
        "## Create training instances by moving sliding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SMQURKM_2dXJ"
      },
      "outputs": [],
      "source": [
        "def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n",
        "    \"\"\"\n",
        "    data: numpy array including data\n",
        "    window_size: size of window\n",
        "    inputs_cols_indices: col indices to include\n",
        "    \"\"\"\n",
        "\n",
        "    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
        "    inputs = np.zeros((len(data) - window_size, window_size, len(inputs_cols_indices)))\n",
        "    labels = np.zeros(len(data) - window_size)\n",
        "\n",
        "    for i in range(window_size, len(data)):\n",
        "        inputs[i - window_size] = data[i - window_size : i, inputs_cols_indices]\n",
        "        labels[i - window_size] = data[i, label_col_index]\n",
        "    inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n",
        "    labels = labels.reshape(-1, 1)\n",
        "    print(inputs.shape, labels.shape)\n",
        "\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKJNbRbc2p4e"
      },
      "source": [
        "## Integrate files to build the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THdZgTDA2mZn",
        "outputId": "6e3d30df-5f6c-4c94-9c01-a79e8a28ae54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing PJMW_hourly.csv ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:02<00:11,  2.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(143116, 90, 5) (143116, 1)\n",
            "Processing pjm_hourly_est.csv ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:07<00:10,  3.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(178172, 90, 5) (178172, 1)\n",
            "Processing PJM_Load_hourly.csv ...\n",
            "(32806, 90, 5) (32806, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:07<00:04,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing DAYTON_hourly.csv ...\n",
            "(121185, 90, 5) (121185, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [00:10<00:02,  2.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing NI_hourly.csv ...\n",
            "(58360, 90, 5) (58360, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n"
          ]
        }
      ],
      "source": [
        "label_col_index = 0  # consumption as label to predict\n",
        "inputs_cols_indices = range(\n",
        "    5\n",
        ")  # use (consumption, hour, dayofweek, month, dayofyear) columns as features\n",
        "\n",
        "# Define window_size period and split inputs/labels\n",
        "window_size = 90\n",
        "\n",
        "# The scaler objects will be stored in this dictionary so that our output test data from the model can be re-scaled during evaluation\n",
        "label_scalers = {}\n",
        "\n",
        "train_x = []\n",
        "test_x = {}\n",
        "test_y = {}\n",
        "\n",
        "# Skipping the files we're not using\n",
        "processing_files = [\n",
        "    file for file in os.listdir(data_dir) if os.path.splitext(file)[1] == \".csv\"\n",
        "]\n",
        "\n",
        "num_files_for_dataset = 5\n",
        "\n",
        "for file in tqdm(processing_files[:num_files_for_dataset]):\n",
        "    print(f\"Processing {file} ...\")\n",
        "    # Store csv file in a Pandas DataFrame\n",
        "    df = pd.read_csv(os.path.join(data_dir, file), parse_dates=[\"Datetime\"])\n",
        "\n",
        "    # Processing the time data into suitable input formats\n",
        "    df[\"hour\"] = df.apply(lambda x: x[\"Datetime\"].hour, axis=1)\n",
        "    df[\"dayofweek\"] = df.apply(lambda x: x[\"Datetime\"].dayofweek, axis=1)\n",
        "    df[\"month\"] = df.apply(lambda x: x[\"Datetime\"].month, axis=1)\n",
        "    df[\"dayofyear\"] = df.apply(lambda x: x[\"Datetime\"].dayofyear, axis=1)\n",
        "    df = df.sort_values(\"Datetime\").drop(\"Datetime\", axis=1)\n",
        "\n",
        "    # Scaling the input data\n",
        "    sc = MinMaxScaler()\n",
        "    label_sc = MinMaxScaler()\n",
        "    data = sc.fit_transform(df.values)\n",
        "\n",
        "    # Obtaining the scaler for the labels(usage data) so that output can be\n",
        "    # re-scaled to actual value during evaluation\n",
        "    label_sc.fit(df.iloc[:, label_col_index].values.reshape(-1, 1))\n",
        "    label_scalers[file] = label_sc\n",
        "\n",
        "    # Move the window\n",
        "    inputs, labels = move_sliding_window(\n",
        "        data,\n",
        "        window_size,\n",
        "        inputs_cols_indices=inputs_cols_indices,\n",
        "        label_col_index=label_col_index,\n",
        "    )\n",
        "\n",
        "    # CONCAT created instances from all .csv files.\n",
        "    # Split data into train/test portions and combining all data from different files into a single array\n",
        "    test_portion = int(0.1 * len(inputs))\n",
        "    if len(train_x) == 0:  # first iteration\n",
        "        train_x = inputs[:-test_portion]\n",
        "        train_y = labels[:-test_portion]\n",
        "    else:\n",
        "        train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
        "        train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
        "    test_x[file] = inputs[-test_portion:]\n",
        "    test_y[file] = labels[-test_portion:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfHYoAXB2_L4"
      },
      "source": [
        "## What have we made?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDvHVfNp2uwM",
        "outputId": "cb87e4e5-72bf-44fd-dc77-0ceb73682c41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((480277, 90, 5), (14311, 90, 5))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x.shape, test_x[\"PJMW_hourly.csv\"].shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBoTV0kq3Z6c"
      },
      "source": [
        "## Pytorch data loaders/ generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NZp_64pO3ArN"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "\n",
        "# Drop the last incomplete batch\n",
        "train_loader = DataLoader(\n",
        "    train_data, shuffle=True, batch_size=batch_size, drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tCHFf6833e28"
      },
      "outputs": [],
      "source": [
        "# release some memory\n",
        "del train_x, train_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JR-xpYws3gF3"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZofaHMK4-uG"
      },
      "source": [
        "# Model & Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCA3S6UL5XlR"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HsKk6Y_f3h0-"
      },
      "outputs": [],
      "source": [
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
        "        super(GRUNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.gru(x, h)\n",
        "        # print(out[:, -1].shape, h.shape)\n",
        "        # select hidden state of last timestamp (t=90) (1024, 256)\n",
        "        out = self.fc(self.relu(out[:, -1]))  # out[:, -1, :]\n",
        "        # print(out.shape) # (1024, 1)\n",
        "        return out, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Initialze h_0 with zeros\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (\n",
        "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
        "        )\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.lstm(x, h)\n",
        "        out = self.fc(self.relu(out[:, -1]))\n",
        "        return out, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        # Initialze h_0, c_0 with zeros\n",
        "        hidden = (\n",
        "            weight.new(self.n_layers, batch_size, self.hidden_dim)\n",
        "            .zero_()\n",
        "            .to(device),  # h_0\n",
        "            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "        )\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLo3gmFk5ZTS"
      },
      "source": [
        "## Build Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YRfg875H5CUP"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    train_loader,\n",
        "    learn_rate,\n",
        "    hidden_dim=256,\n",
        "    n_layers=2,\n",
        "    n_epochs=5,\n",
        "    model_type=\"GRU\",\n",
        "    print_every=100,\n",
        "):\n",
        "\n",
        "    input_dim = next(iter(train_loader))[0].shape[2]  # 5\n",
        "\n",
        "    # Batch generator (train_data, train_label)\n",
        "    # print(next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape) # torch.Size([1024, 90, 5]) torch.Size([1024, 1])\n",
        "\n",
        "    output_dim = 1\n",
        "\n",
        "    # Instantiating the models\n",
        "    if model_type == \"GRU\":\n",
        "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
        "    else:\n",
        "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
        "    model.to(device)\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion = nn.MSELoss()  # Mean Squared Error\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    model.train()\n",
        "    print(\"Starting Training of {} model\".format(model_type))\n",
        "    epoch_times = []\n",
        "\n",
        "    # Start training loop\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        start_time = time.process_time()\n",
        "        h = model.init_hidden(batch_size)\n",
        "        avg_loss = 0.0\n",
        "        counter = 0\n",
        "        for x, label in train_loader:\n",
        "            counter += 1\n",
        "            if model_type == \"GRU\":\n",
        "                h = h.data\n",
        "            # Unpcak both h_0 and c_0\n",
        "            elif model_type == \"LSTM\":\n",
        "                h = tuple([e.data for e in h])\n",
        "\n",
        "            # Set the gradients to zero before starting to do backpropragation because\n",
        "            # PyTorch accumulates the gradients on subsequent backward passes\n",
        "            model.zero_grad()\n",
        "\n",
        "            out, h = model(x.to(device).float(), h)\n",
        "            loss = criterion(out, label.to(device).float())\n",
        "\n",
        "            # Perform backpropragation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "            if counter % print_every == 0:\n",
        "                print(\n",
        "                    f\"Epoch {epoch} - Step: {counter}/{len(train_loader)} - Average Loss for Epoch: {avg_loss/counter}\"\n",
        "                )\n",
        "        current_time = time.process_time()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{n_epochs} Done, Total Loss: {avg_loss/len(train_loader)}\"\n",
        "        )\n",
        "\n",
        "        print(f\"Time Elapsed for Epoch: {current_time-start_time} seconds\")\n",
        "\n",
        "        epoch_times.append(current_time - start_time)\n",
        "\n",
        "    print(f\"Total Training Time: {sum(epoch_times)} seconds\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3wVJzaR5b5c"
      },
      "source": [
        "## Training and Save the GRU model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "_2Qt9ZkF5UWS",
        "outputId": "1a528db1-48f0-4381-dcd4-6ee6a238d055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training of GRU model\n",
            "Epoch 1 - Step: 100/469 - Average Loss for Epoch: nan\n",
            "Epoch 1 - Step: 200/469 - Average Loss for Epoch: nan\n"
          ]
        }
      ],
      "source": [
        "# seq_len = 90  # (timestamps)\n",
        "n_hidden = 256\n",
        "n_layers = 2\n",
        "n_epochs = 5\n",
        "print_every = 100\n",
        "lr = 0.001\n",
        "gru_model = train(\n",
        "    train_loader,\n",
        "    learn_rate=lr,\n",
        "    hidden_dim=n_hidden,\n",
        "    n_layers=n_layers,\n",
        "    n_epochs=n_epochs,\n",
        "    model_type=\"GRU\",\n",
        "    print_every=print_every,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA09Vg-26RlY"
      },
      "outputs": [],
      "source": [
        "torch.save(gru_model.state_dict(), \"./model/gru_model.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOzE6Hmv5WAW"
      },
      "source": [
        "## Training and Save the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr9n2waa5gI4"
      },
      "outputs": [],
      "source": [
        "lstm_model = train(\n",
        "    train_loader,\n",
        "    learn_rate=lr,\n",
        "    hidden_dim=n_hidden,\n",
        "    n_layers=n_layers,\n",
        "    n_epochs=n_epochs,\n",
        "    model_type=\"LSTM\",\n",
        "    print_every=print_every,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-f1uuHh6Lnd"
      },
      "outputs": [],
      "source": [
        "torch.save(lstm_model.state_dict(), \"./model/lstm_model.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-SuB1Vg6lzn"
      },
      "source": [
        "# Evaluating Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWf3iRIZ6wJH"
      },
      "source": [
        "## Loading the GRU model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHWI1-2K6nxb"
      },
      "outputs": [],
      "source": [
        "# move device to cpu for evaluation to avoid GPU memory run\n",
        "device = \"gpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-74UK8t6ppL"
      },
      "outputs": [],
      "source": [
        "## input_dim = next(iter(train_loader))[0].shape[2]  # 5\n",
        "## train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "## train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "hidden_dim = 256\n",
        "input_dim = 5\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "gru_model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
        "gru_model.load_state_dict(torch.load(\"./model/gru_model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIDBGjW76sDh"
      },
      "outputs": [],
      "source": [
        "# Move the model to the appropriate device\n",
        "gru_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiGYT8MJ60qs"
      },
      "source": [
        "## Load the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFSpOWwg6tuL"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 256\n",
        "input_dim = 5\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "lstm_model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
        "lstm_model.load_state_dict(torch.load(\"./model/lstm_model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogFPcEmW64VC"
      },
      "outputs": [],
      "source": [
        "# Move the model to the appropriate device\n",
        "lstm_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hogCP6kr66MV"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhy9vTfd65ft"
      },
      "outputs": [],
      "source": [
        "def sMAPE(outputs, targets):\n",
        "    sMAPE = (\n",
        "        100\n",
        "        / len(targets)\n",
        "        * np.sum(np.abs(outputs - targets) / (np.abs(outputs + targets)) / 2)\n",
        "    )\n",
        "    return sMAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUKGDN8S7C0_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_x, test_y, label_scalers):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    targets = []\n",
        "    start_time = time.process_time()\n",
        "    # get data of test data for each state\n",
        "    for file in test_x.keys():\n",
        "        inputs = torch.from_numpy(np.array(test_x[file]))\n",
        "        labels = torch.from_numpy(np.array(test_y[file]))\n",
        "\n",
        "        h = model.init_hidden(inputs.shape[0])\n",
        "\n",
        "        # predict outputs\n",
        "        with torch.no_grad():\n",
        "            out, h = model(inputs.to(device).float(), h)\n",
        "\n",
        "        outputs.append(\n",
        "            label_scalers[file]\n",
        "            .inverse_transform(out.cpu().detach().numpy())\n",
        "            .reshape(-1)\n",
        "        )\n",
        "\n",
        "        targets.append(\n",
        "            label_scalers[file].inverse_transform(labels.numpy()).reshape(-1)\n",
        "        )\n",
        "\n",
        "    # Merge all files\n",
        "    concatenated_outputs = np.concatenate(outputs)\n",
        "    concatenated_targets = np.concatenate(targets)\n",
        "\n",
        "    print(f\"Evaluation Time: {time.process_time()-start_time}\")\n",
        "    print(f\"sMAPE: {round(sMAPE(concatenated_outputs, concatenated_targets), 3)}%\")\n",
        "\n",
        "    # list of of targets/outputs for each state\n",
        "    return outputs, targets, sMAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYJG8yu97rHa"
      },
      "source": [
        "# Evaluate performance of GRU & LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h01zFmHN7E5o"
      },
      "outputs": [],
      "source": [
        "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UagtJg6R7toG"
      },
      "outputs": [],
      "source": [
        "lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhlhLdc97yiQ"
      },
      "outputs": [],
      "source": [
        "len(\n",
        "    gru_outputs\n",
        ")  # list of predicted output file for each state (each element has a 1d array for that state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ8DSYcg71fC"
      },
      "source": [
        "# Some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdzONNho70pe"
      },
      "outputs": [],
      "source": [
        "states_list = list(test_x.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi8BTiP174NY"
      },
      "outputs": [],
      "source": [
        "states_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9Hl0sMD7496"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
        "plt.plot(\n",
        "    lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2\n",
        ")\n",
        "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
        "plt.ylabel(\"Energy Consumption (MW)\")\n",
        "plt.title(f\"Energy Consumption for {states_list[0]} state\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
        "plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
        "plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n",
        "plt.ylabel(\"Energy Consumption (MW)\")\n",
        "plt.title(f\"Energy Consumption for {states_list[1]} state\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
        "plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
        "plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n",
        "plt.ylabel(\"Energy Consumption (MW)\")\n",
        "plt.title(f\"Energy Consumption for {states_list[2]} state\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
        "plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
        "plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n",
        "plt.title(f\"Energy Consumption for {states_list[3]} state\")\n",
        "plt.ylabel(\"Energy Consumption (MW)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kLhzU_v77Ew"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
